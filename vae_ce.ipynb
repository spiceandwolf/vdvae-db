{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from pythae.models import AutoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_data(task,plot_figures=True):\n",
    "    assert task in ['mnist','cifar']\n",
    "    if task=='cifar':\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        cifar_trainset = datasets.CIFAR10(root='../../data', download=True, transform=transform)\n",
    "        train_dataset = np.transpose(cifar_trainset.data[:-10000],(0,3,1,2))/255\n",
    "        eval_dataset = np.transpose(cifar_trainset.data[-10000:],(0,3,1,2))/255\n",
    "        all_dataset = np.transpose(cifar_trainset.data,(0,3,1,2))/255\n",
    "        print('train_dataset shape:',train_dataset.shape)\n",
    "        if plot_figures:\n",
    "            fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(5, 5))\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    axes[i][j].imshow(np.transpose(train_dataset[i*5+j],(1,2,0)))\n",
    "                    axes[i][j].axis('off')\n",
    "        return train_dataset,eval_dataset,all_dataset\n",
    "    elif task=='mnist':\n",
    "        mnist_trainset = datasets.MNIST(root='../../data', download=True, transform=None)\n",
    "        train_dataset = mnist_trainset.data[:-10000].reshape(-1, 1, 28, 28) / 255.\n",
    "        eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255.\n",
    "        all_dataset=mnist_trainset.data.reshape(-1, 1, 28, 28) / 255.\n",
    "        print('train_dataset shape:',train_dataset.shape)\n",
    "        if plot_figures:\n",
    "            fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(5, 5))\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    axes[i][j].imshow(train_dataset[i*5 +j].cpu().squeeze(0), cmap='gray')\n",
    "                    axes[i][j].axis('off')\n",
    "        return train_dataset,eval_dataset,all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional, Union\n",
    "\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from pythae.data.datasets import BaseDataset\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# make it print to the console.\n",
    "console = logging.StreamHandler()\n",
    "logger.addHandler(console)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    This is a basic class which preprocesses the data.\n",
    "    Basically, it takes messy data, detects potential nan, bad types end convert the\n",
    "    data to a type handled by the VAE models (*i.e.* `torch.Tensor`). Moreover, if the\n",
    "    data does not have the same shape, a reshaping is applied and data is resized to the\n",
    "    **minimal shape**.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def process_data(\n",
    "        self, data: Union[np.ndarray, torch.Tensor], batch_size: int = 100\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"This function detects potential check the data type, detects nan in input data and\n",
    "        preprocessed the data so it can be handled by the models.\n",
    "\n",
    "        Args:\n",
    "            data (Union[np.ndarray, torch.Tensor]): The data that need to be\n",
    "                checked. Expected:\n",
    "\n",
    "                    - | np.ndarray of shape `num_data x n_channels x [optional depth] x\n",
    "                      | [optional height] x width x ...`\n",
    "                    - | torch.Tensor of shape `num_data x n_channels x [optional depth] x\n",
    "                      | [optional height] x width x ...`\n",
    "\n",
    "            batch_size (int): The batch size used for data preprocessing\n",
    "\n",
    "        Returns:\n",
    "            clean_data (torch.tensor): The data that has been cleaned\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(data, np.ndarray) or torch.is_tensor(data):\n",
    "            data = self._process_data_array(data, batch_size=batch_size)\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Wrong data type provided. Expected one of \"\n",
    "                \"[np.ndarray, torch.Tensor]\"\n",
    "            )\n",
    "\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dataset(data: torch.Tensor, labels: Optional[torch.Tensor] = None):\n",
    "        \"\"\"This method converts a set of ``torch.Tensor`` to a\n",
    "        :class:`~pythae.data.datasets.BaseDataset`\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): The set of data as a big torch.Tensor\n",
    "            labels (torch.Tensor): The targets labels as a big torch.Tensor\n",
    "\n",
    "        Returns:\n",
    "            (BaseDataset): The resulting dataset\n",
    "        \"\"\"\n",
    "\n",
    "        if labels is None:\n",
    "            labels = torch.ones(data.shape[0])\n",
    "\n",
    "        labels = DataProcessor.to_tensor(labels)\n",
    "        dataset = BaseDataset(data, labels)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def _process_data_array(self, data: np.ndarray, batch_size: int = 100):\n",
    "\n",
    "        num_samples = data.shape[0]\n",
    "        samples_shape = data.shape\n",
    "\n",
    "        num_complete_batch = num_samples // batch_size\n",
    "        num_in_last = num_samples % batch_size\n",
    "\n",
    "        full_data = []\n",
    "\n",
    "        for i in range(num_complete_batch):\n",
    "\n",
    "            # Detect potential nan\n",
    "            if DataProcessor.has_nan(data[i * batch_size : (i + 1) * batch_size]):\n",
    "                raise ValueError(\"Nan detected in input data!\")\n",
    "\n",
    "            processed_data = DataProcessor.to_tensor(\n",
    "                data[i * batch_size : (i + 1) * batch_size]\n",
    "            )\n",
    "            full_data.append(processed_data)\n",
    "\n",
    "        if num_in_last > 0:\n",
    "            # Detect potential nan\n",
    "            if DataProcessor.has_nan(data[-num_in_last:]):\n",
    "                raise ValueError(\"Nan detected in input data!\")\n",
    "\n",
    "            processed_data = DataProcessor.to_tensor(data[-num_in_last:])\n",
    "            full_data.append(processed_data)\n",
    "\n",
    "        processed_data = torch.cat(full_data)\n",
    "\n",
    "        assert processed_data.shape == samples_shape, (data.shape, num_samples)\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    @staticmethod\n",
    "    def to_tensor(data: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"Converts numpy arrays to `torch.Tensor` format\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The data to be converted\n",
    "\n",
    "        Return:\n",
    "            (torch.Tensor): The transformed data\"\"\"\n",
    "\n",
    "        # check input type\n",
    "        if not torch.is_tensor(data):\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError(\n",
    "                    \" Data must be either of type \"\n",
    "                    f\"< 'torch.Tensor' > or < 'np.ndarray' > ({type(data)} provided). \"\n",
    "                    f\" Check data\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    data = torch.tensor(data).type(torch.float)\n",
    "\n",
    "                except (TypeError, RuntimeError) as e:\n",
    "                    raise TypeError(\n",
    "                        str(e.args) + \". Potential issues:\\n\"\n",
    "                        \"- input data has not the same shape in array\\n\"\n",
    "                        \"- input data with unhandable type\"\n",
    "                    ) from e\n",
    "\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def has_nan(data: torch.Tensor) -> bool:\n",
    "        \"\"\"Detects potential nan in input data\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): The data to be checked\n",
    "\n",
    "        Return:\n",
    "            (bool): True if data contains :obj:`nan`\n",
    "        \"\"\"\n",
    "\n",
    "        if (data != data).sum() > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_model(model_name,task):\n",
    "    assert model_name in ['vae','rae_gp']\n",
    "    assert task in ['mnist','cifar']\n",
    "    if task=='mnist':\n",
    "        input_dim=(1,28,28)\n",
    "        latent_dim=16\n",
    "        if model_name=='vae':\n",
    "            from pythae.models import VAE, VAEConfig\n",
    "            from pythae.models.nn.benchmarks.mnist import Encoder_ResNet_VAE_MNIST, Decoder_ResNet_AE_MNIST\n",
    "            model_config = VAEConfig(\n",
    "                input_dim=input_dim,\n",
    "                latent_dim=latent_dim\n",
    "            )\n",
    "            model = VAE(\n",
    "                model_config=model_config,\n",
    "                encoder=Encoder_ResNet_VAE_MNIST(model_config), \n",
    "                decoder=Decoder_ResNet_AE_MNIST(model_config) \n",
    "            )\n",
    "        elif model_name=='rae_gp':\n",
    "            from pythae.models import RAE_GP, RAE_GP_Config\n",
    "            from pythae.models.nn.benchmarks.mnist import Encoder_ResNet_AE_MNIST, Decoder_ResNet_AE_MNIST\n",
    "            model_config = RAE_GP_Config(\n",
    "                    input_dim=input_dim,\n",
    "                    latent_dim=latent_dim, # mnist 16\n",
    "                    embedding_weight=1e-2,\n",
    "                    reg_weight=1e-4\n",
    "                )\n",
    "            model = RAE_GP(\n",
    "                model_config=model_config,\n",
    "                encoder=Encoder_ResNet_AE_MNIST(model_config), \n",
    "                decoder=Decoder_ResNet_AE_MNIST(model_config) \n",
    "            )\n",
    "    elif task=='cifar':\n",
    "        input_dim=(3,32,32)\n",
    "        latent_dim=128\n",
    "        if model_name=='vae':\n",
    "            from pythae.models import VAE, VAEConfig\n",
    "            from pythae.models.nn.benchmarks.cifar import Encoder_ResNet_VAE_CIFAR, Decoder_ResNet_AE_CIFAR\n",
    "            model_config = VAEConfig(\n",
    "                input_dim=input_dim,\n",
    "                latent_dim=latent_dim\n",
    "            )\n",
    "            model = VAE(\n",
    "                model_config=model_config,\n",
    "                encoder=Encoder_ResNet_VAE_CIFAR(model_config), \n",
    "                decoder=Decoder_ResNet_AE_CIFAR(model_config) \n",
    "            )\n",
    "        elif model_name=='rae_gp':\n",
    "            from pythae.models import RAE_GP, RAE_GP_Config\n",
    "            from pythae.models.nn.benchmarks.cifar import Encoder_ResNet_AE_CIFAR, Decoder_ResNet_AE_CIFAR\n",
    "            model_config = RAE_GP_Config(\n",
    "                    input_dim=input_dim,\n",
    "                    latent_dim=latent_dim, # mnist 16\n",
    "                    embedding_weight=1e-2,\n",
    "                    reg_weight=1e-4\n",
    "                )\n",
    "            model = RAE_GP(\n",
    "                model_config=model_config,\n",
    "                encoder=Encoder_ResNet_AE_CIFAR(model_config), \n",
    "                decoder=Decoder_ResNet_AE_CIFAR(model_config) \n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "model_name='rae_gp'\n",
    "task='mnist'\n",
    "output_dir='my_model/{}/{}/'.format(task,model_name)\n",
    "config= BaseTrainerConfig(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=4096,\n",
    "    num_epochs=100, # Change this to train the model a bit more\n",
    ")\n",
    "\n",
    "train_dataset,eval_dataset,all_dataset=get_figure_data(task)\n",
    "model=get_figure_model(model_name,task)\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    training_config=config,\n",
    "    model=model\n",
    ")\n",
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid=FrechetInceptionDistance(feature=2048).to(device)\n",
    "fid.eval()\n",
    "\n",
    "def evaluate(pred, target):\n",
    "    pred=pred.to(device)\n",
    "    target=target.to(device)\n",
    "    print('pred shape: ',pred.shape)\n",
    "    print('target shape: ',target.shape)\n",
    "    with  torch.no_grad():\n",
    "        metric = {}\n",
    "        batch_size = 512\n",
    "        imgs_dist1 = (pred.mul(255).add(0.5).clamp(0, 255)).type(torch.uint8)\n",
    "        imgs_dist2 = (target.mul(255).add(0.5).clamp(0, 255)).type(torch.uint8)\n",
    "        if imgs_dist1.shape[1] == 1: \n",
    "            imgs_dist1 = imgs_dist1.repeat(1, 3, 1, 1)\n",
    "        if imgs_dist2.shape[1] == 1:\n",
    "            imgs_dist2 = imgs_dist2.repeat(1, 3, 1, 1)\n",
    "        # fid.reset()\n",
    "        for idx in tqdm(range(0, len(pred), batch_size)):\n",
    "            fid.update(imgs_dist1[idx:idx+batch_size], real=False)\n",
    "            fid.update(imgs_dist2[idx:idx+batch_size], real=True)\n",
    "        metric[\"FID\"] = fid.compute()\n",
    "        print('FID : {}'.format(metric[\"FID\"].cpu().item()))\n",
    "        \n",
    "def plot_figures(images,output_dir=None,file_name=None):\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(2, 2))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if images.shape[1]==1:\n",
    "                axes[i][j].imshow(images[i*5+j].cpu().squeeze(0),cmap='gray')\n",
    "            else:\n",
    "                axes[i][j].imshow(np.transpose(images[i*5+j].cpu(),(1,2,0)))\n",
    "            axes[i][j].axis('off')\n",
    "    plt.tight_layout(pad=0.)\n",
    "    if output_dir is not None:\n",
    "        fig.savefig(os.path.join(output_dir,file_name))\n",
    "        \n",
    "def get_sampler(sampler,model,train_dataset=None):\n",
    "    assert sampler in ['normal','gmm']\n",
    "    if sampler=='normal':\n",
    "        from pythae.samplers import NormalSampler\n",
    "        normal_samper = NormalSampler(model=model)\n",
    "        return normal_samper\n",
    "    elif sampler=='gmm':\n",
    "        assert train_dataset is not None\n",
    "        from pythae.samplers import GaussianMixtureSampler, GaussianMixtureSamplerConfig,NormalSampler\n",
    "        gmm_sampler_config = GaussianMixtureSamplerConfig(n_components=30)\n",
    "        gmm_sampler = GaussianMixtureSampler(sampler_config=gmm_sampler_config,model=model)\n",
    "        print('fitting gmm sampler, this process could take several mins')\n",
    "        gmm_sampler.fit(train_dataset)\n",
    "        return gmm_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCP_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(c, c // r, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(c // r, c, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, _, _ = x.shape\n",
    "        y = self.squeeze(x).view(bs, c)\n",
    "        y = self.excitation(y).view(bs, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "class ResidualBlockA(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlockA, self).__init__()\n",
    "        assert out_channels==in_channels \n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm2d(in_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        SE_Block(out_channels))   \n",
    "        self.out_channels = out_channels\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class ResidualBlockB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlockB, self).__init__()\n",
    "        assert out_channels==2*in_channels\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm2d(in_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        SE_Block(out_channels))\n",
    "        self.factorized_reduction=nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=2,padding=0)\n",
    "        self.out_channels = out_channels\n",
    "        self.swish=SE_Block(in_channels)\n",
    "    def forward(self, x):\n",
    "        # print('residualB')\n",
    "        # print('x shape',x.shape)\n",
    "        residual = self.swish(x)\n",
    "        residual=self.factorized_reduction(residual)\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        # print('out shape',out.shape)\n",
    "        return out\n",
    "\n",
    "class Binary_Classifier(nn.Module):\n",
    "    def __init__(self, blockA, blockB, inchannel):\n",
    "        super(Binary_Classifier, self).__init__()\n",
    "        self.inplanes = inchannel\n",
    "        # self.linear1=nn.Linear(16,self.inplanes*16*16)\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #                 nn.ConvTranspose2d(self.inplanes, self.inplanes, 3, 2, padding=1),\n",
    "        #                 nn.ReLU())\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(self.inplanes, self.inplanes, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.ReLU())\n",
    "        self.layer0 = self._make_layer(blockA, self.inplanes, self.inplanes, 3)\n",
    "        self.layer1 = self._make_layer(blockB, self.inplanes, self.inplanes * 2, 1)\n",
    "        self.layer2 = self._make_layer(blockA, self.inplanes * 2, self.inplanes * 2, 3)\n",
    "        self.layer3 = self._make_layer(blockB, self.inplanes * 2, self.inplanes * 4,1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.inplanes * 4, 1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def _make_layer(self, block, in_channels,out_channels, blocks):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x=self.linear1(x)\n",
    "        # x=x.reshape(x.shape[0],self.inplanes,16,16)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer0(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        # print('layer1 out',x.shape)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "class NCP_VAE(nn.Module):\n",
    "    def __init__(self,sampler,bin_classifier):\n",
    "        super(NCP_VAE, self).__init__()\n",
    "        self.sampler=sampler\n",
    "        self.bin_classifier=bin_classifier\n",
    "        self.fid=FrechetInceptionDistance(feature=2048).to(device)\n",
    "        self.fid.eval()\n",
    "        self.bin_classifier.eval()\n",
    "        self.device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_reweight(self,z):\n",
    "        x=self.sampler.model.decoder(z)[\"reconstruction\"].detach()\n",
    "        D=self.bin_classifier(x)\n",
    "        r=D/(1-D)\n",
    "        return r\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_from_p(self,num_samples):\n",
    "        \"\"\"sample from gaussian mixture\"\"\"\n",
    "        try:\n",
    "            z=torch.tensor(self.sampler.gmm.sample(num_samples)[0]).type(torch.float).to(self.device)\n",
    "        except Exception:\n",
    "            z=torch.randn(num_samples, self.sampler.model.latent_dim).to(self.device)\n",
    "        return z\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_from_q(self,input):\n",
    "        z=self.sampler.model(input).z.detach().to(device)\n",
    "        return z\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_from_ncp(self,num_samples):\n",
    "        z=self.sample_from_p(num_samples)\n",
    "        r=self.get_reweight(z).reshape(-1,)\n",
    "        r/=r.sum()\n",
    "        idx=torch.multinomial(r,num_samples)\n",
    "        return z[idx]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self,num_samples):\n",
    "        z=self.sample_from_ncp(num_samples)\n",
    "        return self.sampler.model.decoder(z)[\"reconstruction\"].detach()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self,real_set,num_samples):\n",
    "        target=real_set[:num_samples]\n",
    "        pred=self.sample(num_samples)\n",
    "        metric = {}\n",
    "        batch_size = 16\n",
    "        imgs_dist1 = (pred.mul(255).add(0.5).clamp(0, 255)).type(torch.uint8).to(self.device)\n",
    "        imgs_dist2 = (target.mul(255).add(0.5).clamp(0, 255)).type(torch.uint8).to(self.device)\n",
    "        if imgs_dist1.shape[1] == 1: \n",
    "            imgs_dist1 = imgs_dist1.repeat(1, 3, 1, 1)\n",
    "        if imgs_dist2.shape[1] == 1:\n",
    "            imgs_dist2 = imgs_dist2.repeat(1, 3, 1, 1)\n",
    "        # fid.reset()\n",
    "        for idx in tqdm(range(0, len(pred), batch_size)):\n",
    "            fid.update(imgs_dist1[idx:idx+batch_size], real=False)\n",
    "            fid.update(imgs_dist2[idx:idx+batch_size], real=True)\n",
    "        # print(\"fake_samples: \", fid.fake_features_num_samples)\n",
    "        # print(\"real_samples: \", fid.real_features_num_samples)\n",
    "        metric[\"FID\"] = fid.compute()\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='rae_gp'\n",
    "task='mnist'\n",
    "output_dir='my_model/{}/{}/'.format(task,model_name)\n",
    "last_training = sorted(os.listdir(output_dir))[-1]\n",
    "output_dir=os.path.join(output_dir, last_training, 'final_model')\n",
    "trained_model = AutoModel.load_from_folder(output_dir)\n",
    "train_dataset,eval_dataset,all_dataset=get_figure_data(task)\n",
    "sampler_gmm=get_sampler('gmm',trained_model,train_dataset)\n",
    "\n",
    "train_dataset,eval_dataset,all_dataset=get_figure_data(task)\n",
    "data_processor = DataProcessor()\n",
    "train_data_processed = data_processor.process_data(train_dataset).to(device)\n",
    "train_dataset_processed = data_processor.to_dataset(train_data_processed)\n",
    "train_loader = DataLoader(dataset=train_dataset_processed, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_ncp(sampler,data_loader,epochs=10,bs=1024,lr=0.001):\n",
    "    binary_classifier=Binary_Classifier(ResidualBlockA,ResidualBlockB,3 if task=='cifar' else 1).to(device)\n",
    "    optimizer=torch.optim.Adam(binary_classifier.parameters(),lr=lr)\n",
    "    criterion=nn.BCELoss()\n",
    "    for epoch in range(epochs):\n",
    "        acc=[]\n",
    "        losses=[]\n",
    "        for batch in data_loader:\n",
    "            num_samples=len(batch['data'])\n",
    "            q=sampler.model(batch).recon_x\n",
    "            # p_=torch.tensor(gmm_sampler.gmm.sample(num_samples)[0]).type(torch.float).to(device)\n",
    "            p=sampler.sample(num_samples)\n",
    "            input=torch.cat((q,p),dim=0)\n",
    "            labels=torch.cat((torch.ones(num_samples),torch.zeros(num_samples))).to(device)\n",
    "            out=binary_classifier(input).squeeze()\n",
    "            loss=criterion(out,labels) \n",
    "            acc.append(np.mean(np.array(out.cpu()>0.5)==np.array(labels.cpu())))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            losses.append(loss.cpu().item())\n",
    "            optimizer.step()\n",
    "        print('Eopoch :{} | Acc : {:.3f} | Loss : {:.3f} '.format(epoch,np.mean(acc),np.mean(losses)))\n",
    "\n",
    "    ncp_vae=NCP_VAE(sampler,binary_classifier)\n",
    "    fid_scores=[]\n",
    "    # print('acc: ',np.mean(acc))\n",
    "    print(\"Evaluation ncp_vae\")\n",
    "    for i in range(1):\n",
    "        fid_score=ncp_vae.evaluate(torch.tensor(all_dataset),int(0.1 * len(all_dataset)))['FID'].cpu().item()\n",
    "        fid_scores.append(fid_score)\n",
    "    print('FID : {}, avg: {:.3F}'.format(fid_scores,np.mean(fid_scores)))\n",
    "    return ncp_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncp_vae_sampler_gmm=train_eval_ncp(sampler_gmm,train_loader,50,lr=0.01)\n",
    "\n",
    "plot_figures(ncp_vae_sampler_gmm.sample(25),output_dir,'ncp_rae_gmm_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POWER Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import torch\n",
    "from my_utils import plot_hist_marginals\n",
    "from pythae.data.datasets import DatasetOutput, BaseDataset\n",
    "\n",
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Wraps a Table and yields each row to use in pythae.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, perc_miss = 0.5):\n",
    "        '''\n",
    "        Args:\n",
    "            data: dataframe.\n",
    "        '''\n",
    "        super(TableDataset, self).__init__()\n",
    "        self.tuples_np = np.stack([Discretize(c) for c in data.Columns()], axis=1)\n",
    "        self.tuples = torch.as_tensor(self.tuples_np.astype(np.float32, copy=False))\n",
    "        # self.data = self.tuples\n",
    "        self.onehot_data_np = One_hot(self.tuples_np)\n",
    "        self.onehot_data = torch.as_tensor(self.onehot_data_np, dtype=torch.float32)\n",
    "        # self.data_one_hot = self.__encode_onehot(self.tuples_np, [c.DistributionSize() for c in data.columns])\n",
    "        self.masks_np = Mask_row(self.onehot_data_np, perc_miss)\n",
    "        self.masks = torch.as_tensor(self.masks_np)\n",
    "        \n",
    "    def size(self):\n",
    "        return len(self.tuples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tuples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.tuples[idx]\n",
    "        X_one_hot = self.onehot_data[idx]\n",
    "        masks = self.masks[idx]\n",
    "        return DatasetOutput(\n",
    "            data = X,\n",
    "            data_one_hot = X_one_hot,\n",
    "            masks = masks,\n",
    "        )\n",
    "        \n",
    "    def __encode_onehot(self, data, input_bins):\n",
    "        '''\n",
    "        Args:\n",
    "            data: ndarray.\n",
    "        '''\n",
    "        # print(f'data : {data.keys}')\n",
    "        bs = data.shape[0]\n",
    "        y_onehots = []\n",
    "        data = data.astype(np.int32)\n",
    "        # print(f'input_bins : {input_bins}')\n",
    "        for i, coli_dom_size in enumerate(input_bins):\n",
    "            if coli_dom_size <= 2:\n",
    "                y_onehots.append(data[:, i].reshape(-1, 1).astype(np.float32))\n",
    "            else:\n",
    "                y_onehot = np.zeros((bs, coli_dom_size), dtype=np.int32)\n",
    "                y_onehot[data[:, i].reshape(-1, 1)] = 1\n",
    "                y_onehots.append(y_onehot)\n",
    "        # [bs, sum(dist size)]\n",
    "        return torch.as_tensor(np.concatenate(y_onehots, 1))    \n",
    "    \n",
    "    def show_histograms(self, split):\n",
    "\n",
    "        data_split = getattr(self, split, None)\n",
    "        if data_split is None:\n",
    "            raise ValueError('Invalid data split')\n",
    "\n",
    "        plot_hist_marginals(data_split.x)\n",
    "        plt.show()\n",
    "        \n",
    "    def minmax_normalized(self):\n",
    "        def normalize(x):\n",
    "            return (x - x.min()) / (x.max() - x.min())\n",
    "        self.data = self.data.apply(normalize)\n",
    "    \n",
    "    def spilt_train_valid(self, valid_rate):\n",
    "        N_valid = int(valid_rate * self.data.shape[0])\n",
    "        data_valid = self.data[-N_valid:]\n",
    "        data = self.data[0:-N_valid]\n",
    "        \n",
    "        return data, data_valid    \n",
    "    \n",
    "def Discretize(col, data=None):\n",
    "    \"\"\"Transforms data values into integers using a Column's vocab.\n",
    "\n",
    "    Args:\n",
    "        col: the Column.\n",
    "        data: list-like data to be discretized.  If None, defaults to col.data.\n",
    "\n",
    "    Returns:\n",
    "        col_data: discretized version; an np.ndarray of type np.int32.\n",
    "    \"\"\"\n",
    "    # pd.Categorical() does not allow categories be passed in an array\n",
    "    # containing np.nan.  It makes it a special case to return code -1\n",
    "    # for NaN values.\n",
    "\n",
    "    if data is None:\n",
    "        data = col.data\n",
    "    \n",
    "    # pd.isnull returns true for both np.nan and np.datetime64('NaT').\n",
    "    isnan = pd.isnull(col.all_distinct_values)\n",
    "    if isnan.any():\n",
    "        # We always add nan or nat to the beginning.\n",
    "        assert isnan.sum() == 1, isnan\n",
    "        assert isnan[0], isnan\n",
    "\n",
    "        dvs = col.all_distinct_values[1:]\n",
    "        bin_ids = pd.Categorical(data, categories=dvs).codes\n",
    "        assert len(bin_ids) == len(data)\n",
    "\n",
    "        # Since nan/nat bin_id is supposed to be 0 but pandas returns -1, just\n",
    "        # add 1 to everybody\n",
    "        bin_ids = bin_ids + 1\n",
    "    else:\n",
    "        # This column has no nan or nat values.\n",
    "        dvs = col.all_distinct_values\n",
    "        bin_ids = pd.Categorical(data, categories=dvs).codes\n",
    "        # print(f'dvs : {len(dvs)} bin_ids : {len(np.unique(bin_ids))}')\n",
    "        assert len(bin_ids) == len(data), (len(bin_ids), len(data))\n",
    "\n",
    "    assert (bin_ids >= 0).all(), (col, data, bin_ids)\n",
    "    return bin_ids\n",
    "\n",
    "def One_hot(tuples_np):\n",
    "    onehot_datas = []\n",
    "    for i in range(tuples_np.shape[1]):\n",
    "        onehot_data = pd.get_dummies(tuples_np[:, i]).values\n",
    "        onehot_datas.append(onehot_data)\n",
    "    \n",
    "    return np.concatenate(onehot_datas, 1)\n",
    "\n",
    "def Mask_row(row, perc_miss):\n",
    "    def generate_mask(row):\n",
    "        n = len(row)\n",
    "        mask = np.zeros(n, dtype=bool)\n",
    "        indices = np.random.choice(n, size=int(n * perc_miss), replace=False)\n",
    "        mask[indices] = True\n",
    "        mask[row] = False # the actual values should be observed\n",
    "        return mask\n",
    "    \n",
    "    vectorized_generate_mask = np.vectorize(generate_mask, signature='(n)->(n)')\n",
    "    return vectorized_generate_mask(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tabular import CsvTable, power\n",
    "from train_helpers_tabular import set_up_hyperparams\n",
    "\n",
    "H, logprint = set_up_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = power(H)\n",
    "# print(f'{original_data.data[0:1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = TableDataset(\n",
    "    data=original_data.data\n",
    ")\n",
    "original_dataset.minmax_normalized()\n",
    "train_data, valid_data = original_dataset.spilt_train_valid(0.1)\n",
    "\n",
    "train_dataset = TableDataset(\n",
    "    data=train_data\n",
    ")\n",
    "\n",
    "eval_dataset = TableDataset(\n",
    "    data=valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        assert out_channels==in_channels \n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(in_channels, middle_channels, kernel_size = 3, stride = 1, padding = 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(middle_channels),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(middle_channels, out_channels, kernel_size = 3, stride = 1, padding = 1))   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class Encoder_Conv_VAE_Power(BaseEncoder):\n",
    "    def __init__(self, args):\n",
    "        BaseEncoder.__init__(self)\n",
    "\n",
    "        self.input_dim = (1, 7)\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.n_channels = 1\n",
    "\n",
    "        self.input_layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(self.n_channels, 16, 3, 1, 1),\n",
    "        )\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock(16, 4, 16) for _ in range(2)]\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Linear(16 * 7, args.latent_dim)\n",
    "        self.log_var = nn.Linear(16 * 7, args.latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h1 = self.input_layers(x)\n",
    "        h2 = self.residual_layers(h1)\n",
    "        h3 = h2.reshape(x.shape[0], -1)\n",
    "        output = ModelOutput(\n",
    "            embedding=self.embedding(h3),\n",
    "            log_covariance=self.log_var(h3)\n",
    "        )\n",
    "        return output\n",
    "    \n",
    "class Decoder_Conv_VAE_Power(BaseDecoder):\n",
    "    def __init__(self, args):\n",
    "        BaseDecoder.__init__(self)\n",
    "        self.input_dim = (1, 7)\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.n_channels = 1\n",
    "\n",
    "        self.fc = nn.Linear(args.latent_dim, 16 * 7)\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock(16, 4, 16) for _ in range(2)]\n",
    "        )\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, self.n_channels, 3, 1, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        h1 = self.fc(z).reshape(z.shape[0], 16, 7)\n",
    "        h2 = self.residual_layers(h1)\n",
    "        h3 = self.output_layers(h2)\n",
    "        output = ModelOutput(reconstruction=h3)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models import VAEConfig\n",
    "\n",
    "model_config = VAEConfig(\n",
    "    input_dim=(1, 7),\n",
    "    latent_dim=16\n",
    "    )\n",
    "\n",
    "encoder = Encoder_Conv_VAE_Power(model_config)\n",
    "decoder= Decoder_Conv_VAE_Power(model_config)\n",
    "\n",
    "from typing import Optional\n",
    "from pythae.models import VAE\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE_CE(VAE):\n",
    "    def __init__(self,\n",
    "        model_config: VAEConfig,\n",
    "        encoder: Optional[BaseEncoder] = None,\n",
    "        decoder: Optional[BaseDecoder] = None,):\n",
    "        \n",
    "        super().__init__(model_config, encoder, decoder)\n",
    "\n",
    "    def get_nll_batch(self, data, n_samples=1):\n",
    "        \"\"\"\n",
    "        Function computed the estimate negative log-likelihood of the model. It uses importance\n",
    "        sampling method with the approximate posterior distribution. This may take a while.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): The input data from which the log-likelihood should be estimated.\n",
    "                Data must be of shape [Batch x n_channels x ...]\n",
    "            n_samples (int): The number of importance samples to use for estimation\n",
    "        \"\"\"\n",
    "        log_p_x = []\n",
    "\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            encoder_output = self.encoder(data)\n",
    "            mu, log_var = encoder_output.embedding, encoder_output.log_covariance\n",
    "\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            z, _ = self._sample_gauss(mu, std)\n",
    "\n",
    "            log_q_z_given_x = -0.5 * (\n",
    "                log_var + (z - mu) ** 2 / torch.exp(log_var)\n",
    "            ).sum(dim=-1, keepdim=True) # shape [B x 1]\n",
    "            log_p_z = -0.5 * (z ** 2).sum(dim=-1, keepdim=True) # shape [B x 1]\n",
    "            \n",
    "            # print(f'log_q_z_given_x: {log_q_z_given_x.shape}')\n",
    "            # print(f'log_p_z: {log_p_z.shape}')\n",
    "\n",
    "            recon_x = self.decoder(z)[\"reconstruction\"]\n",
    "\n",
    "            if self.model_config.reconstruction_loss == \"mse\":\n",
    "\n",
    "                log_p_x_given_z = -0.5 * torch.log(F.mse_loss(\n",
    "                    recon_x.reshape(data.shape[0], -1),\n",
    "                    data.reshape(data.shape[0], -1),\n",
    "                    reduction=\"none\",\n",
    "                )).sum(dim=-1) - torch.tensor(\n",
    "                    [np.prod(self.input_dim) / 2 * np.log(np.pi * np.e * 2)]\n",
    "                ).to(\n",
    "                    data.device\n",
    "                )  # decoding distribution is assumed unit variance  N(mu, I)\n",
    "\n",
    "            elif self.model_config.reconstruction_loss == \"bce\":\n",
    "\n",
    "                log_p_x_given_z = -F.binary_cross_entropy(\n",
    "                    recon_x.reshape(data.shape[0], -1),\n",
    "                    data.reshape(data.shape[0], -1),\n",
    "                    reduction=\"none\",\n",
    "                ).sum(dim=-1)\n",
    "\n",
    "            log_p_x.append(\n",
    "                    log_p_x_given_z + log_p_z - log_q_z_given_x\n",
    "                )  # log(2*pi) simplifies\n",
    "\n",
    "        log_p_x = torch.cat(log_p_x, dim=1) # [B x n_samples]\n",
    "        # print(f'log_p_x: {log_p_x.shape}')\n",
    "        \n",
    "        return torch.logsumexp(log_p_x, dim=1) - np.log(n_samples)\n",
    "        \n",
    "model = VAE_CE(\n",
    "    model_config=model_config,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines import TrainingPipeline\n",
    "\n",
    "training_config = BaseTrainerConfig(\n",
    "    output_dir='./saved_models/power_test/test_-1',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    steps_saving=None,\n",
    "    num_epochs=10)\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    model=model,\n",
    "    training_config=training_config)\n",
    "\n",
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythae.models import AutoModel\n",
    "# import os\n",
    "# last_training = sorted(os.listdir('./saved_models/power_test/test_-1'))[-1]\n",
    "# model_rec = AutoModel.load_from_folder(os.path.join('./saved_models/power_test/test_-1', last_training, 'final_model'))\n",
    "# model.__class__ = VAE_CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from my_utils import Card, ErrorMetric, GenerateQuery, estimate_probabilities, make_points\n",
    "\n",
    "def eval_power(model):\n",
    "    table = original_data\n",
    "    rng = np.random.RandomState(1234)\n",
    "    count = 0\n",
    "    n_rows = table.data.shape[0] - int(table.data.shape[0] * 0.1) \n",
    "    # n_rows = table.data.shape[0] \n",
    "    qerrors = []\n",
    "\n",
    "    for i in range(3000):\n",
    "            \n",
    "        cols, ops, vals = GenerateQuery(table.columns, rng, table.data)\n",
    "        true_card = Card(table.data[:int(table.data.shape[0] * 0.9)], cols, ops, vals)\n",
    "        # true_card = Card(table.data, cols, ops, vals)\n",
    "        predicates = []\n",
    "        for c, o, v in zip(cols, ops, vals):\n",
    "            predicates.append((c, o, v))\n",
    "                \n",
    "        left_bounds = {}\n",
    "        right_bounds = {}\n",
    "        \n",
    "        for idx, attr in enumerate(table.columns):\n",
    "            col_name = attr.name   \n",
    "            left_bounds[col_name] = table.mins[idx]\n",
    "            right_bounds[col_name] = table.maxs[idx] \n",
    "                \n",
    "        table_stats = (table.columns, table.name_to_index, right_bounds, left_bounds)\n",
    "        \n",
    "        # print(predicates)\n",
    "        integration_domain = make_points(table_stats, predicates, table.bias, None, 'minmax')\n",
    "        \n",
    "        # print(integration_domain)\n",
    "        def pdf(x):\n",
    "            nll = model.get_nll_batch(x)\n",
    "            \n",
    "            # print(f'nll: {nll.shape}')\n",
    "            return nll\n",
    "        \n",
    "        prob = estimate_probabilities(pdf, integration_domain, len(table.columns)).item()\n",
    "        # print(f'prob: {prob}')\n",
    "        \n",
    "        if  math.isnan(prob):\n",
    "            est_card = 1\n",
    "            count += 1\n",
    "        elif  math.isinf(prob):   \n",
    "            est_card = n_rows if prob > 0 else 1\n",
    "            count += 1\n",
    "        else:\n",
    "            est_card = max(prob * n_rows, 1)\n",
    "            \n",
    "            if est_card > n_rows:\n",
    "                count += 1\n",
    "                est_card = n_rows\n",
    "                # print(f'prob {prob} true_card: {true_card}')\n",
    "            \n",
    "        qerror = ErrorMetric(est_card, true_card)\n",
    "        qerrors.append(qerror)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'{i} queries done')\n",
    "    \n",
    "    return count, qerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, qerrors = eval_power(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'estimation failed times: {count}')\n",
    "print('test results')\n",
    "print(f\"Median: {np.median(qerrors)}\")\n",
    "print(f\"90th percentile: {np.percentile(qerrors, 90)}\")\n",
    "print(f\"95th percentile: {np.percentile(qerrors, 95)}\")\n",
    "print(f\"99th percentile: {np.percentile(qerrors, 99)}\")\n",
    "print(f\"Max: {np.max(qerrors)}\")\n",
    "print(f\"Mean: {np.mean(qerrors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256\n",
    "estimation failed times: 2275\n",
    "test results\n",
    "Median: 61.312145072691465\n",
    "90th percentile: 13137.085710979565\n",
    "95th percentile: 54245.64705882353\n",
    "99th percentile: 461327.5539670102\n",
    "Max: 1844352.0\n",
    "Mean: 19325.10150461067\n",
    "\n",
    "16\n",
    "2层\n",
    "estimation failed times: 1686\n",
    "test results\n",
    "Median: 16.94870361887311\n",
    "90th percentile: 3575.8930232558123\n",
    "95th percentile: 14070.845913264851\n",
    "99th percentile: 154568.74266167908\n",
    "Max: 1844352.0\n",
    "Mean: 9211.902219659025\n",
    "8层\n",
    "estimation failed times: 2269\n",
    "test results\n",
    "Median: 55.58625678119349\n",
    "90th percentile: 13733.809901449096\n",
    "95th percentile: 48126.172612388735\n",
    "99th percentile: 461088.0\n",
    "Max: 1844352.0\n",
    "Mean: 18189.851955382997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(c, c // r, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(c // r, c, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, _ = x.shape\n",
    "        y = self.squeeze(x).view(bs, c)\n",
    "        y = self.excitation(y).view(bs, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "class ResidualBlockA(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlockA, self).__init__()\n",
    "        assert out_channels == in_channels \n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv1d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(out_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        SE_Block(out_channels))   \n",
    "        self.out_channels = out_channels\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class ResidualBlockB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlockB, self).__init__()\n",
    "        assert out_channels == 2 * in_channels\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv1d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(out_channels),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        SE_Block(out_channels))\n",
    "        self.factorized_reduction=nn.Conv1d(in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.out_channels = out_channels\n",
    "        self.swish = SE_Block(in_channels)\n",
    "    def forward(self, x):\n",
    "        # print('residualB')\n",
    "        # print('x shape',x.shape)\n",
    "        residual = self.swish(x)\n",
    "        residual = self.factorized_reduction(residual)\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        # print('out shape',out.shape)\n",
    "        return out\n",
    "\n",
    "class Binary_Classifier(nn.Module):\n",
    "    def __init__(self, blockA, blockB, inchannel):\n",
    "        super(Binary_Classifier, self).__init__()\n",
    "        self.inplanes = inchannel\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv1d(self.inplanes, self.inplanes, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.ReLU())\n",
    "        self.layer0 = self._make_layer(blockA, self.inplanes, self.inplanes, 3)\n",
    "        self.layer1 = self._make_layer(blockB, self.inplanes, self.inplanes * 2, 1)\n",
    "        self.layer2 = self._make_layer(blockA, self.inplanes * 2, self.inplanes * 2, 3)\n",
    "        self.layer3 = self._make_layer(blockB, self.inplanes * 2, self.inplanes * 4, 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(self.inplanes * 4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def _make_layer(self, block, in_channels, out_channels, blocks):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x=self.linear1(x)\n",
    "        # x=x.reshape(x.shape[0],self.inplanes,16,16)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer0(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        # print('layer1 out',x.shape)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "class NCP_VAE(nn.Module):\n",
    "    def __init__(self, sampler, bin_classifier):\n",
    "        super(NCP_VAE, self).__init__()\n",
    "        self.sampler = sampler\n",
    "        self.bin_classifier = bin_classifier\n",
    "        self.bin_classifier.eval()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_reweight(self, z):\n",
    "        x = self.sampler.model.decoder(z)[\"reconstruction\"].detach()\n",
    "        D = self.bin_classifier(x)\n",
    "        r = D / (1 - D)\n",
    "        return r\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_from_p(self, num_samples):\n",
    "        \"\"\"sample from gaussian mixture\"\"\"\n",
    "        try:\n",
    "            z = torch.tensor(self.sampler.gmm.sample(num_samples)[0]).type(torch.float).to(self.device)\n",
    "        except Exception:\n",
    "            z = torch.randn(num_samples, self.sampler.model.latent_dim).to(self.device)\n",
    "        return z\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_from_q(self, input):\n",
    "        z = self.sampler.model(input).z.detach().to(device)\n",
    "        return z\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _sample_from_ncp(self, num_samples):\n",
    "        z = self.sample_from_p(num_samples)\n",
    "        r = self.get_reweight(z).reshape(-1,)\n",
    "        r /= r.sum()\n",
    "        idx = torch.multinomial(r, num_samples)\n",
    "        return z[idx]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples):\n",
    "        z = self._sample_from_ncp(num_samples)\n",
    "        return self.sampler.model.decoder(z)[\"reconstruction\"].detach()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_nll_batch(self, data, n_samples=1):\n",
    "        log_p_x = []\n",
    "\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            encoder_output = self.sampler.model.encoder(data)\n",
    "            mu, log_var = encoder_output.embedding, encoder_output.log_covariance\n",
    "\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            z, _ = self.sampler.model._sample_gauss(mu, std)\n",
    "            r = self.get_reweight(z).reshape(-1,)\n",
    "            r /= r.sum()\n",
    "            idx = torch.multinomial(r, z.shape[0])\n",
    "            z = z[idx]\n",
    "\n",
    "            log_q_z_given_x = -0.5 * (\n",
    "                log_var + (z - mu) ** 2 / torch.exp(log_var)\n",
    "            ).sum(dim=-1, keepdim=True) # shape [B x 1]\n",
    "            log_p_z = -0.5 * (z ** 2).sum(dim=-1, keepdim=True) # shape [B x 1]\n",
    "            \n",
    "            # print(f'log_q_z_given_x: {log_q_z_given_x.shape}')\n",
    "            # print(f'log_p_z: {log_p_z.shape}')\n",
    "\n",
    "            recon_x = self.sampler.model.decoder(z)[\"reconstruction\"]\n",
    "\n",
    "            if self.sampler.model.model_config.reconstruction_loss == \"mse\":\n",
    "\n",
    "                log_p_x_given_z = -0.5 * torch.log(F.mse_loss(\n",
    "                    recon_x.reshape(data.shape[0], -1),\n",
    "                    data.reshape(data.shape[0], -1),\n",
    "                    reduction=\"none\",\n",
    "                )).sum(dim=-1) - torch.tensor(\n",
    "                    [np.prod(self.sampler.model.input_dim) / 2 * np.log(np.pi * np.e * 2)]\n",
    "                ).to(\n",
    "                    data.device\n",
    "                )  # decoding distribution is assumed unit variance  N(mu, I)\n",
    "\n",
    "            elif self.sampler.model.model_config.reconstruction_loss == \"bce\":\n",
    "\n",
    "                log_p_x_given_z = -F.binary_cross_entropy(\n",
    "                    recon_x.reshape(data.shape[0], -1),\n",
    "                    data.reshape(data.shape[0], -1),\n",
    "                    reduction=\"none\",\n",
    "                ).sum(dim=-1)\n",
    "\n",
    "            log_p_x.append(\n",
    "                    log_p_x_given_z + log_p_z - log_q_z_given_x\n",
    "                )  # log(2*pi) simplifies\n",
    "\n",
    "        log_p_x = torch.cat(log_p_x, dim=1) # [B x n_samples]\n",
    "        # print(f'log_p_x: {log_p_x.shape}')\n",
    "        \n",
    "        return torch.logsumexp(log_p_x, dim=1) - np.log(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ncp(sampler, data_loader, epochs=10, lr=0.001):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    binary_classifier = Binary_Classifier(ResidualBlockA, ResidualBlockB, 1).to(device)\n",
    "    optimizer = torch.optim.Adam(binary_classifier.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(epochs):\n",
    "        acc = []\n",
    "        losses = []\n",
    "        for batch in data_loader:\n",
    "            num_samples = len(batch['data'])\n",
    "            q = sampler.model(batch).recon_x\n",
    "            p = sampler.sample(num_samples)\n",
    "            input = torch.cat((q, p), dim=0)\n",
    "            labels = torch.cat((torch.ones(num_samples), torch.zeros(num_samples))).to(device)\n",
    "            out = binary_classifier(input).squeeze()\n",
    "            loss = criterion(out, labels) \n",
    "            acc.append(np.mean(np.array(out.cpu() > 0.5) == np.array(labels.cpu())))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            losses.append(loss.cpu().item())\n",
    "            optimizer.step()\n",
    "        print('Eopoch :{} | Acc : {:.3f} | Loss : {:.3f} '.format(epoch,np.mean(acc),np.mean(losses)))\n",
    "\n",
    "    ncp_vae = NCP_VAE(sampler,binary_classifier)\n",
    "    \n",
    "    return ncp_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "labels = torch.ones(train_dataset.tuples.shape[0]).cuda()\n",
    "dataset = BaseDataset(train_dataset.tuples.cuda(), labels)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "from pythae.samplers import NormalSampler\n",
    "\n",
    "normal_samper = NormalSampler(model=model)\n",
    "ncp_vae_sampler_normal = train_ncp(normal_samper, train_loader, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, qerrors = eval_power(ncp_vae_sampler_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'estimation failed times: {count}')\n",
    "print('test results')\n",
    "print(f\"Median: {np.median(qerrors)}\")\n",
    "print(f\"90th percentile: {np.percentile(qerrors, 90)}\")\n",
    "print(f\"95th percentile: {np.percentile(qerrors, 95)}\")\n",
    "print(f\"99th percentile: {np.percentile(qerrors, 99)}\")\n",
    "print(f\"Max: {np.max(qerrors)}\")\n",
    "print(f\"Mean: {np.mean(qerrors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CE based on Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import data_tabular\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def power():\n",
    "    csv_file = os.path.join('../dataset/', 'household_power_consumption.txt')\n",
    "    cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3']\n",
    "    trX = data_tabular.CsvTable('power', csv_file, cols, sep=';', na_values=[' ', '?'], header=0, dtype=np.float64)  \n",
    "    # print(trX.data.shape)    \n",
    "\n",
    "    return trX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = power()\n",
    "# print(original_data.data.isna().any(axis=1))\n",
    "input_bins = [c.DistributionSize() for c in original_data.columns]\n",
    "# print(input_bins)\n",
    "table = TableDataset(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calss TableDataset's verification\n",
    "\n",
    "# print(table[10000]['data'])\n",
    "# print(table[10000]['data_one_hot'].shape)\n",
    "# j = 0\n",
    "# for i in range(len(input_bins)):\n",
    "#     j += 0 if i == 0 else input_bins[int(i) - 1]\n",
    "#     print(table[10000]['data_one_hot'][int(table[10000]['data'][i] + j)])\n",
    "# print(table[10000]['masks'].shape)    \n",
    "# print(table[10000]['masks'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "from pydantic.dataclasses import dataclass\n",
    "from pythae.config import BaseConfig\n",
    "from typing_extensions import Literal\n",
    "\n",
    "@dataclass\n",
    "class MissIWAEConfig(BaseConfig):\n",
    "    \"\"\"MissIWAE model config class.\n",
    "\n",
    "    Parameters:\n",
    "        input_dim (tuple): The input_data dimension.\n",
    "        latent_dim (int): The latent space dimension. Default: None.\n",
    "        reconstruction_loss (str): The reconstruction loss to use ['bce', 'mse']. Default: 'mse'\n",
    "        number_samples (int): Number of samples to use on the Monte-Carlo estimation. Default: 10\n",
    "    \"\"\"\n",
    "\n",
    "    reconstruction_loss: Literal[\"bce\", \"mse\", \"obsce\"] = \"mse\"\n",
    "    number_samples: int = 100\n",
    "    input_dim: int = 1\n",
    "    output_dim: int = 1\n",
    "    latent_dim: int = 10\n",
    "    hidden_dim: int = 256\n",
    "    input_bins: Union[Tuple[int, ...], None] = None\n",
    "    perc_miss: float = 0.\n",
    "    embedding_dim: int = 64\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIWAE_FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResBlock_FC(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(ResBlock_FC, self).__init__()\n",
    "        assert out_channels==in_channels \n",
    "        self.linear_layer1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(in_channels, middle_channels, bias=False))\n",
    "        self.linear_layer2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(middle_channels),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(middle_channels, out_channels, bias=False))   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.linear_layer1(x)\n",
    "        out = self.linear_layer2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "    \n",
    "class Encoder_FC_MissIWAE_Power(BaseEncoder):\n",
    "    def __init__(self, args):\n",
    "        BaseEncoder.__init__(self)\n",
    "\n",
    "        self.input_dim = args.input_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.embedding_dim = args.embedding_dim\n",
    "        self.register_buffer('position_ids', torch.arange(self.input_dim) / self.input_dim)\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.embedding_dim, bias=False),\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim, bias=False),\n",
    "        )\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock_FC(self.hidden_dim, int(self.hidden_dim / 4), self.hidden_dim) for _ in range(2)]\n",
    "        )\n",
    "\n",
    "        self.posterior = nn.Linear(self.hidden_dim, 2 * self.latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \n",
    "        out = self.input_layer(x + self.position_ids) # (bs, hidden_dim)\n",
    "        out = self.residual_layers(out) # (bs, hidden_dim)\n",
    "        out = self.posterior(out) # (bs, latent_dim * 2)\n",
    "        embedding, log_covariance = torch.split(out, self.latent_dim, dim=-1)\n",
    "        output = ModelOutput(\n",
    "            embedding=embedding,\n",
    "            log_covariance=log_covariance\n",
    "        )\n",
    "        return output\n",
    "    \n",
    "class Decoder_FC_MissIWAE_Power(BaseDecoder):\n",
    "    def __init__(self, args):\n",
    "        BaseDecoder.__init__(self)\n",
    "        \n",
    "        self.output_dim = args.output_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.latent_dim = args.latent_dim\n",
    "\n",
    "        self.prior = nn.Linear(self.latent_dim, self.hidden_dim, bias=False)\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock_FC(self.hidden_dim, int(self.hidden_dim / 4), self.hidden_dim) for _ in range(2)]\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        out = self.prior(z)\n",
    "        out = self.residual_layers(out)\n",
    "        out = self.output_layer(out)\n",
    "        output = ModelOutput(reconstruction=out)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIWAE_Conv\n",
    "\n",
    "slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models import VAE\n",
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "from pythae.data.datasets import BaseDataset\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock_Conv(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(ResBlock_Conv, self).__init__()\n",
    "        assert out_channels==in_channels \n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(in_channels),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(in_channels, middle_channels, kernel_size = 3, stride = 1, padding = 1, bias=False))\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.BatchNorm1d(middle_channels),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(middle_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias=False))   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class Encoder_Conv_MissIWAE_Power(BaseEncoder):\n",
    "    def __init__(self, args):\n",
    "        BaseEncoder.__init__(self)\n",
    "\n",
    "        self.n_channels = 1\n",
    "        self.input_dim = args.input_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.latent_dim = args.latent_dim\n",
    "\n",
    "        self.input_layers = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
    "        self.fc2conv = nn.Conv1d(self.n_channels, self.hidden_dim, self.hidden_dim, bias=False)\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock_Conv(self.hidden_dim, int(self.hidden_dim / 4), self.hidden_dim) for _ in range(2)]\n",
    "        )\n",
    "        self.posterior = nn.Conv1d(self.hidden_dim, self.latent_dim * 2, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        The Encoder_Conv\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): (bs, n_features,)\n",
    "\n",
    "        Returns:\n",
    "            ModelOutput: An instance of ModelOutput containing all the relevant parameters\n",
    "\n",
    "        \"\"\"\n",
    "        out = self.input_layers(x).unsqueeze(1) # (bs, 1, hidden_dim)\n",
    "        out = self.fc2conv(out) # (bs, hidden_dim, 1)\n",
    "        out = self.residual_layers(out) # (bs, hidden_dim, 1)\n",
    "        out = self.posterior(out) # (bs, latent_dim * 2, 1)\n",
    "        embedding, log_covariance = torch.split(out, self.latent_dim, dim=1)\n",
    "        output = ModelOutput(\n",
    "            embedding=embedding.reshape(x.shape[0], -1),\n",
    "            log_covariance=log_covariance.reshape(x.shape[0], -1)\n",
    "        )\n",
    "        return output\n",
    "    \n",
    "class Decoder_Conv_MissIWAE_Power(BaseDecoder):\n",
    "    def __init__(self, args):\n",
    "        BaseDecoder.__init__(self)\n",
    "        \n",
    "        self.n_channels = 1\n",
    "        self.output_dim = args.output_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.latent_dim = args.latent_dim\n",
    "\n",
    "        self.prior = nn.Conv1d(self.latent_dim, self.hidden_dim, 1, 1, 0, bias=False)\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResBlock_Conv(self.hidden_dim, int(self.hidden_dim / 4), self.hidden_dim) for _ in range(2)]\n",
    "        )\n",
    "        self.conv2fc = nn.ConvTranspose1d(self.hidden_dim, self.n_channels, self.hidden_dim)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        \"\"\"\n",
    "        The Decoder_Conv\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): (bs * n_samples, latent_dim,)\n",
    "\n",
    "        Returns:\n",
    "            ModelOutput: An instance of ModelOutput containing all the relevant parameters\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        out = self.prior(z.reshape(z.shape[0], self.latent_dim, -1)) # (bs * n_samples, hidden_dim, 1)\n",
    "        out = self.residual_layers(out) # (bs * n_samples, hidden_dim, 1)\n",
    "        out = self.conv2fc(out) # (bs * n_samples, 1, hidden_dim)\n",
    "        out = self.output_layer(out.reshape(z.shape[0], -1)) # (bs * n_samples, output_dim)\n",
    "        output = ModelOutput(reconstruction=out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MissIWAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pythae.models import VAE\n",
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "from pythae.data.datasets import BaseDataset\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MissIWAE(VAE):\n",
    "    \"\"\"\n",
    "    MissIWAE is based on the Importance Weighted Autoencoder model, maximises a potentially tight lower bound of the log-likelihood of the observed data.\n",
    "\n",
    "    Args:\n",
    "        model_config (MissIWAEConfig): The IWAE configuration setting the main\n",
    "            parameters of the model.\n",
    "\n",
    "        encoder (BaseEncoder): An instance of BaseEncoder (inheriting from `torch.nn.Module` which\n",
    "            plays the role of encoder. This argument allows you to use your own neural networks\n",
    "            architectures if desired. If None is provided, a simple Multi Layer Preception\n",
    "            (https://en.wikipedia.org/wiki/Multilayer_perceptron) is used. Default: None.\n",
    "\n",
    "        decoder (BaseDecoder): An instance of BaseDecoder (inheriting from `torch.nn.Module` which\n",
    "            plays the role of decoder. This argument allows you to use your own neural networks\n",
    "            architectures if desired. If None is provided, a simple Multi Layer Preception\n",
    "            (https://en.wikipedia.org/wiki/Multilayer_perceptron) is used. Default: None.\n",
    "\n",
    "    .. note::\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_config: MissIWAEConfig,\n",
    "        encoder: Optional[BaseEncoder] = None,\n",
    "        decoder: Optional[BaseDecoder] = None,\n",
    "    ):\n",
    "\n",
    "        VAE.__init__(self, model_config=model_config, encoder=encoder, decoder=decoder)\n",
    "\n",
    "        self.model_name = \"MissIWAE\"\n",
    "        self.n_samples = model_config.number_samples\n",
    "        self.mask = None\n",
    "        self.input_bins = model_config.input_bins\n",
    "        # print(f'input_bins {self.input_bins}')\n",
    "\n",
    "    def forward(self, inputs: BaseDataset, **kwargs):\n",
    "        \"\"\"\n",
    "        The VAE model\n",
    "\n",
    "        Args:\n",
    "            inputs (BaseDataset): The training dataset with labels\n",
    "\n",
    "        Returns:\n",
    "            ModelOutput: An instance of ModelOutput containing all the relevant parameters\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        x = inputs[\"data\"] # (bs, n_dims)\n",
    "        # print(f'x {x.device}')\n",
    "        # xb = self._encode_onehot(x, self.input_bins) # (bs, n_features)\n",
    "        xb = inputs[\"data_one_hot\"]\n",
    "        \n",
    "        # miss_pattern = torch.randperm(xb.numel())[:int(xb.numel() * self.model_config.perc_miss)]\n",
    "        # x_coords, y_coords = torch.div(miss_pattern, xb.shape[1], rounding_mode='floor'), miss_pattern % xb.shape[1]\n",
    "        # mask = torch.zeros(xb.shape, dtype=torch.bool, device='cpu') # (bs, n_features)\n",
    "        # mask[x_coords, y_coords] = 1\n",
    "        # xbhat = xb.clone().detach()\n",
    "        mask = inputs[\"masks\"]\n",
    "        \n",
    "        # mask[xb.bool()] = 0 # the actual values should be observed\n",
    "        xb[mask.bool()] = 0.5 # in xbhat, the missing values are represented by 0.5\n",
    "        \n",
    "        # self.mask = mask.unsqueeze(-1) # (bs, n_features, 1)\n",
    "        self.mask = mask.unsqueeze(-1).to(device=xb.device)\n",
    "        \n",
    "        encoder_output = self.encoder(xb)\n",
    "\n",
    "        mu, log_var = encoder_output.embedding, encoder_output.log_covariance\n",
    "\n",
    "        mu = mu.unsqueeze(1).repeat(1, self.n_samples, 1)\n",
    "        log_var = log_var.unsqueeze(1).repeat(1, self.n_samples, 1)\n",
    "        # print(f'mu : {mu.shape}')\n",
    "        # print(f'log_var : {log_var.shape}')\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "\n",
    "        z, _ = self._sample_gauss(mu, std)\n",
    "\n",
    "        recon_xb = self.decoder(z.reshape(-1, self.latent_dim))[\n",
    "            \"reconstruction\"\n",
    "        ].reshape(x.shape[0], -1, self.n_samples) # (bs, n_features, n_samples)\n",
    "        # print(f'recon_xb : {recon_xb.shape}')\n",
    "        \n",
    "        loss, recon_loss, kld = self.loss_function(recon_xb, xb, mu, log_var, z) # binary_cross_entropy_with_logits\n",
    "        # loss, recon_loss, kld = self.loss_function(recon_xb, x, mu, log_var, z) # cross_entropy\n",
    "        \n",
    "        recon_x = torch.zeros((x.shape[0], self.n_samples, x.shape[1]), device=x.device) # (bs, n_samples, n_dims)\n",
    "        # for i, coli_dom_size in enumerate(self.input_bins):\n",
    "        #     # colis = recon_xb[:, :, start : start + coli_dom_size]\n",
    "        #     probs_is = torch.softmax(self.mask * recon_xb[:, start : start + coli_dom_size, :], 1).mean(-1) # (bs, input_bin in n_features)\n",
    "        #     # print(f'prodbs_is: {probs_is.shape}')\n",
    "        #     recon_x[:, :, i] = torch.multinomial(probs_is, num_samples=self.n_samples, replacement=True)  # (bs, num_samples, i in n_dims)\n",
    "        #     start += coli_dom_size\n",
    "       \n",
    "        output = ModelOutput(\n",
    "            recon_loss=recon_loss,\n",
    "            reg_loss=kld,\n",
    "            loss=loss,\n",
    "            recon_x=recon_x.reshape(x.shape[0], self.n_samples, -1)[:, 0, :].reshape_as(\n",
    "                x\n",
    "            ),\n",
    "            z=z.reshape(x.shape[0], self.n_samples, -1)[:, 0, :].reshape(\n",
    "                -1, self.latent_dim\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, log_var, z):\n",
    "        \"\"\"\n",
    "        loss function\n",
    "\n",
    "        Args:\n",
    "            recon_x (tensor): (bs, n_features, n_samples)\n",
    "            x (tensor): (bs, n_features) -> binary_cross_entropy_with_logits or (bs, n_dims) -> cross_entropy\n",
    "            mu (tensor): (bs, n_samples, latent_dim)\n",
    "            log_var (tensor): (bs, n_samples, latent_dim)\n",
    "            z (tensor): (bs, n_samples, latent_dim)\n",
    "\n",
    "        Returns:\n",
    "            elbo, recon_loss, kld\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.model_config.reconstruction_loss == \"mse\":\n",
    "\n",
    "            recon_loss = (\n",
    "                0.5\n",
    "                * F.mse_loss(\n",
    "                    recon_x,\n",
    "                    x.reshape(recon_x.shape[0], -1)\n",
    "                    .unsqueeze(1)\n",
    "                    .repeat(1, self.n_samples, 1),\n",
    "                    reduction=\"none\",\n",
    "                ).sum(dim=-1)\n",
    "            )\n",
    "\n",
    "        elif self.model_config.reconstruction_loss == \"bce\":\n",
    "\n",
    "            recon_loss = F.binary_cross_entropy(\n",
    "                recon_x,\n",
    "                x.reshape(recon_x.shape[0], -1)\n",
    "                .unsqueeze(1)\n",
    "                .repeat(1, self.n_samples, 1),\n",
    "                reduction=\"none\",\n",
    "            ).sum(dim=-1)\n",
    "            \n",
    "        elif self.model_config.reconstruction_loss == \"obsce\":\n",
    "            \n",
    "            x = x.reshape(recon_x.shape[0], -1).unsqueeze(-1).repeat(1, 1, self.n_samples) # (bs, n_dims, n_samples) or (bs, n_features, n_samples)\n",
    "            if x.shape == recon_x.shape:\n",
    "                # mask ->(bs, n_features, 1) * entropy -> (bs, n_features, n_samples)\n",
    "                # softmax each attr's feature then binary_cross_entropy\n",
    "                start = 0\n",
    "                for i in range(len(self.input_bins)):\n",
    "                    recon_x[:, start: start + self.input_bins[i], :] = self._gumbel_softmax(recon_x[:, start: start + self.input_bins[i], :], 1).float()\n",
    "                    start += self.input_bins[i]\n",
    "                    \n",
    "                recon_loss = (\n",
    "                    ~self.mask\n",
    "                    * F.binary_cross_entropy(\n",
    "                        recon_x,\n",
    "                        x,\n",
    "                        reduction=\"none\",   \n",
    "                    ).float() \n",
    "                ).sum(dim=1) # (bs, n_samples)\n",
    "                \n",
    "            else:\n",
    "                recon_loss = torch.zeros(recon_x.size()[0], self.n_samples, device=recon_x.device) # (bs, n_samples)\n",
    "                start = 0\n",
    "                recon_x = ~self.mask * recon_x\n",
    "                for i in range(len(self.input_bins)):\n",
    "                    xb = self._gumbel_softmax(recon_x[:, start: start + self.input_bins[i], :], dim=1).float()\n",
    "                    recon_loss += F.cross_entropy(\n",
    "                       xb,\n",
    "                        x[:, i, :].long(),\n",
    "                        reduction=\"none\",\n",
    "                    )\n",
    "                    start += self.input_bins[i]\n",
    "            \n",
    "        log_q_z = (-0.5 * (log_var + torch.pow(z - mu, 2) / (log_var.exp() + 10e-7))).float().sum(dim=-1) # (bs, n_samples)\n",
    "        log_p_z = -0.5 * (z ** 2).float().sum(dim=-1) # (bs, n_samples)\n",
    "\n",
    "        KLD = -(log_p_z - log_q_z)\n",
    "\n",
    "        log_w = -(recon_loss + KLD).float() # (bs, n_samples)\n",
    "\n",
    "        # log_w_minus_max = log_w - log_w.max(1, keepdim=True)[0]\n",
    "        # w = log_w_minus_max.exp()\n",
    "        # w_tilde = (w / w.sum(axis=1, keepdim=True)).detach()\n",
    "        w_tilde = F.log_softmax(log_w, dim=1).exp().detach()\n",
    "\n",
    "        return (\n",
    "            -(w_tilde * log_w).sum(1).mean(),\n",
    "            recon_loss.mean(),\n",
    "            KLD.mean(),\n",
    "        )\n",
    "\n",
    "    def _sample_gauss(self, mu, std):\n",
    "        # Reparametrization trick\n",
    "        # Sample N(0, I)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std, eps\n",
    "    \n",
    "    def _gumbel_softmax(self, logits: torch.Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> torch.Tensor:\n",
    "        gumbels = (\n",
    "            -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "        )  # ~Gumbel(0,1)\n",
    "        gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
    "        y_soft = gumbels.softmax(dim)\n",
    "\n",
    "        if hard:\n",
    "            # Straight through.\n",
    "            index = y_soft.max(dim, keepdim=True)[1]\n",
    "            y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
    "            ret = y_hard - y_soft.detach() + y_soft\n",
    "        else:\n",
    "            # Reparametrization trick.\n",
    "            ret = y_soft\n",
    "        return ret\n",
    "\n",
    "    def _encode_onehot(self, data, input_bins):\n",
    "        '''\n",
    "        Args:\n",
    "            data: tensor.\n",
    "        '''\n",
    "        # print(f'data : {data.keys}')\n",
    "        bs = data.size()[0]\n",
    "        y_onehots = []\n",
    "        data = data.long()\n",
    "        # print(f'input_bins : {input_bins}')\n",
    "        for i, coli_dom_size in enumerate(input_bins):\n",
    "            if coli_dom_size <= 2:\n",
    "                y_onehots.append(data[:, i].view(-1, 1).float())\n",
    "            else:\n",
    "                y_onehot = torch.zeros(bs, coli_dom_size, device=data.device)\n",
    "                y_onehot.scatter_(1, data[:, i].view(-1, 1), 1)\n",
    "                y_onehots.append(y_onehot)\n",
    "        # [bs, sum(dist size)]\n",
    "        return torch.cat(y_onehots, 1)    \n",
    "    \n",
    "    def probe(self, x, mask, n_samples, **kwargs):\n",
    "        \"\"\"\n",
    "        probe\n",
    "\n",
    "        Args:\n",
    "            x (tensor): (bs, n_features) \n",
    "            mask (tensor): (bs, n_features)\n",
    "\n",
    "        Returns:\n",
    "            elbo, recon_loss, kld\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # print(f'x : {x.device}')\n",
    "        encoder_output = self.encoder(x)\n",
    "\n",
    "        mu, log_var = encoder_output.embedding, encoder_output.log_covariance\n",
    "\n",
    "        mu = mu.unsqueeze(1).repeat(1, n_samples, 1)\n",
    "        log_var = log_var.unsqueeze(1).repeat(1, n_samples, 1)\n",
    "\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "\n",
    "        z, _ = self._sample_gauss(mu, std)\n",
    "\n",
    "        recon_x = self.decoder(z.reshape(-1, self.latent_dim))[\n",
    "            \"reconstruction\"\n",
    "        ].reshape(x.shape[0], n_samples, -1) # (bs, n_samples, n_features)\n",
    "        \n",
    "        start = 0\n",
    "        for i in range(len(self.input_bins)):\n",
    "            recon_x[:, start: start + self.input_bins[i], :] = F.softmax(recon_x[:, start: start + self.input_bins[i], :], 1).float()\n",
    "            start += self.input_bins[i]\n",
    "            \n",
    "        recon_loss = (\n",
    "            ~mask\n",
    "            * F.binary_cross_entropy(\n",
    "                recon_x,\n",
    "                x.reshape(recon_x.shape[0], -1).unsqueeze(1).repeat(1, n_samples, 1),\n",
    "                reduction=\"none\",   \n",
    "            ).float() \n",
    "        ).sum(dim=-1) # (bs, n_samples)\n",
    "        \n",
    "        # recon_loss = (\n",
    "        #             ~mask\n",
    "        #             * F.binary_cross_entropy_with_logits(\n",
    "        #                 recon_x,\n",
    "        #                 x.reshape(recon_x.shape[0], -1)\n",
    "        #                 .unsqueeze(1)\n",
    "        #                 .repeat(1, n_samples, 1),\n",
    "        #                 reduction=\"none\",\n",
    "        #             )\n",
    "        #         ).sum(dim=-1)\n",
    "        log_q_z = (-0.5 * (log_var + torch.pow(z - mu, 2) / (log_var.exp() + 10e-8))).sum(dim=-1) # (bs, n_samples)\n",
    "        log_p_z = -0.5 * (z ** 2).sum(dim=-1) # (bs, n_samples)\n",
    "        \n",
    "        imp_weights = F.softmax(recon_loss + log_p_z - log_q_z, 1).reshape(-1, recon_x.shape[0]) # (n_samples, bs)\n",
    "        recon_x = recon_x.reshape(n_samples, recon_x.shape[0], -1) # (n_samples, bs, n_features)\n",
    "        \n",
    "        xm = torch.einsum('ki,kij->ij', imp_weights, recon_x) # (bs, n_features)\n",
    "        # print(f'xm : {xm.shape}')\n",
    "        recon_probe = torch.ones(recon_x.size()[0], 1, device=recon_x.device) # (bs, 1)\n",
    "        start = 0\n",
    "        for i in range(len(self.model_config.input_bins)):\n",
    "            probs_i = F.softmax(xm[:, start : start + self.model_config.input_bins[i]], 1) * mask[:, start : start + self.model_config.input_bins[i]]\n",
    "            probs_i = probs_i.sum(dim=1)\n",
    "            # print(f'probs_i : {probs_i.shape}')\n",
    "            recon_probe *= probs_i\n",
    "            start += self.model_config.input_bins[i]\n",
    "            \n",
    "        return recon_probe.squeeze(-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MissIWAEConfig(\n",
    "    input_dim = sum(input_bins),\n",
    "    latent_dim = 16,\n",
    "    output_dim = sum(input_bins),\n",
    "    hidden_dim = 256,\n",
    "    input_bins = tuple(input_bins),\n",
    "    perc_miss = 0.5,\n",
    "    reconstruction_loss = \"obsce\",\n",
    "    number_samples = 50\n",
    "    )\n",
    "\n",
    "# print(f'input_bins : {tuple(input_bins)}')\n",
    "\n",
    "encoder = Encoder_FC_MissIWAE_Power(model_config)\n",
    "decoder = Decoder_FC_MissIWAE_Power(model_config)\n",
    "'''\n",
    "encoder = Encoder_Conv_MissIWAE_Power(model_config)\n",
    "decoder = Decoder_Conv_MissIWAE_Power(model_config)\n",
    "'''\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = MissIWAE(\n",
    "    model_config = model_config,\n",
    "    encoder = encoder,\n",
    "    decoder = decoder\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user1/QOlab/vdvae/wandb/run-20241107_200452-an2yii88</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spice-neu-edu-cn/vae-ce/runs/an2yii88' target=\"_blank\">honest-leaf-73</a></strong> to <a href='https://wandb.ai/spice-neu-edu-cn/vae-ce' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spice-neu-edu-cn/vae-ce' target=\"_blank\">https://wandb.ai/spice-neu-edu-cn/vae-ce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spice-neu-edu-cn/vae-ce/runs/an2yii88' target=\"_blank\">https://wandb.ai/spice-neu-edu-cn/vae-ce/runs/an2yii88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train dataset...\n",
      "Using Base Trainer\n",
      "\n",
      "! No eval dataset provided ! -> keeping best model on train.\n",
      "\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "Error when calling forward method from model. Potential issues: \n - Wrong model architecture -> check encoder, decoder and metric architecture if you provide yours \n - The data input dimension provided is wrong -> when no encoder, decoder or metric provided, a network is built automatically but requires the shape of the flatten input data.\nException raised: <class 'TypeError'> with message: empty_like(): argument 'input' (position 1) must be Tensor, not MissIWAE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:313\u001b[0m, in \u001b[0;36mBaseTrainer._run_model_sanity_check\u001b[0;34m(self, model, loader)\u001b[0m\n\u001b[1;32m    312\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_inputs_to_device(inputs)\n\u001b[0;32m--> 313\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[12], line 95\u001b[0m, in \u001b[0;36mMissIWAE.forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# print(f'recon_xb : {recon_xb.shape}')\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m loss, recon_loss, kld \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_xb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# binary_cross_entropy_with_logits\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# loss, recon_loss, kld = self.loss_function(recon_xb, x, mu, log_var, z) # cross_entropy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 167\u001b[0m, in \u001b[0;36mMissIWAE.loss_function\u001b[0;34m(self, recon_x, x, mu, log_var, z)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_bins)):\n\u001b[0;32m--> 167\u001b[0m     recon_x[:, start: start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_bins[i], :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gumbel_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_bins\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    168\u001b[0m     start \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_bins[i]\n",
      "Cell \u001b[0;32mIn[12], line 218\u001b[0m, in \u001b[0;36mMissIWAE._gumbel_softmax\u001b[0;34m(logits, tau, hard, eps, dim)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gumbel_softmax\u001b[39m(logits: torch\u001b[38;5;241m.\u001b[39mTensor, tau: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, hard: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, eps: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-10\u001b[39m, dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    217\u001b[0m     gumbels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_contiguous_format\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexponential_()\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m    219\u001b[0m     )  \u001b[38;5;66;03m# ~Gumbel(0,1)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     gumbels \u001b[38;5;241m=\u001b[39m (logits \u001b[38;5;241m+\u001b[39m gumbels) \u001b[38;5;241m/\u001b[39m tau  \u001b[38;5;66;03m# ~Gumbel(logits,tau)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: empty_like(): argument 'input' (position 1) must be Tensor, not MissIWAE",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 62\u001b[0m\n\u001b[1;32m     53\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# with torch.autograd.detect_anomaly():\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     pipeline(\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#         train_data=table,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#         # eval_data=table,\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#         callbacks=callbacks,\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# eval_data=table,\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mimport torch.profiler as profiler\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mwith profiler.profile(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/pythae/pipelines/training.py:235\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, train_data, eval_data, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config, BaseTrainerConfig):\n\u001b[1;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Base Trainer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 235\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mBaseTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided training config is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:139\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, model, train_dataset, eval_dataset, training_config, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# run sanity check on the model\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_main_process:\n\u001b[1;32m    142\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel passed sanity check !\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for training.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vdvae/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:316\u001b[0m, in \u001b[0;36mBaseTrainer._run_model_sanity_check\u001b[0;34m(self, model, loader)\u001b[0m\n\u001b[1;32m    313\u001b[0m     model(train_dataset)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelError(\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when calling forward method from model. Potential issues: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Wrong model architecture -> check encoder, decoder and metric architecture if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou provide yours \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - The data input dimension provided is wrong -> when no encoder, decoder or metric \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovided, a network is built automatically but requires the shape of the flatten \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with message: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    324\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mModelError\u001b[0m: Error when calling forward method from model. Potential issues: \n - Wrong model architecture -> check encoder, decoder and metric architecture if you provide yours \n - The data input dimension provided is wrong -> when no encoder, decoder or metric provided, a network is built automatically but requires the shape of the flatten input data.\nException raised: <class 'TypeError'> with message: empty_like(): argument 'input' (position 1) must be Tensor, not MissIWAE"
     ]
    }
   ],
   "source": [
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines import TrainingPipeline\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "def linear_warmup(warmup_iters):\n",
    "    def f(iteration):\n",
    "        return 1.0 if iteration > warmup_iters else iteration / warmup_iters\n",
    "    return f\n",
    "\n",
    "''''''\n",
    "training_config = BaseTrainerConfig(\n",
    "    output_dir = './saved_models/power_test/imputated_ce',\n",
    "    learning_rate = 1.5e-3,\n",
    "    per_device_train_batch_size = 1024,\n",
    "    per_device_eval_batch_size = 1024,\n",
    "    steps_saving = None,\n",
    "    num_epochs = 10,\n",
    "    train_dataloader_num_workers = 4,\n",
    "    eval_dataloader_num_workers = 4,\n",
    "    optimizer_cls = \"AdamW\",\n",
    "    optimizer_params = {\n",
    "        \"betas\" : (0.99, 0.999),\n",
    "        },\n",
    "    # scheduler_cls = \"OneCycleLR\",\n",
    "    # scheduler_params = {\n",
    "    #     \"pct_start\" : 0.2,\n",
    "    #     \"max_lr\" : 1e-3,\n",
    "    #     \"total_steps\" : 20,\n",
    "    #     },\n",
    "    # amp = True # binary_cross_entropy can not support now\n",
    ")\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    model = model,\n",
    "    training_config = training_config\n",
    ")\n",
    "\n",
    "from pythae.trainers.training_callbacks import WandbCallback\n",
    "\n",
    "callbacks = []\n",
    "wandb_cb = WandbCallback()\n",
    "wandb_cb.setup(\n",
    "    training_config = training_config,\n",
    "    model_config = model_config,\n",
    "    project_name = \"vae-ce\",\n",
    "    entity_name = \"spice-neu-edu-cn\"\n",
    ")\n",
    "callbacks.append(wandb_cb)\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     pipeline(\n",
    "#         train_data=table,\n",
    "#         # eval_data=table,\n",
    "#         callbacks=callbacks,\n",
    "#     )\n",
    "    \n",
    "pipeline(\n",
    "        train_data=table,\n",
    "        # eval_data=table,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "'''\n",
    "import torch.profiler as profiler\n",
    "with profiler.profile(\n",
    "    activities=[\n",
    "        profiler.ProfilerActivity.CPU,\n",
    "        profiler.ProfilerActivity.CUDA],  # 分析 CPU 和 CUDA 活动\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,  # 前1步不采样\n",
    "        warmup=1,  # 第2步作为热身，不计入结果\n",
    "        active=3,  # 采集后面3步的性能数据\n",
    "        repeat=2),  # 重复2轮\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./runs'),  # 保存日志以供 TensorBoard 可视化\n",
    "    record_shapes=True,  # 记录输入张量的形状\n",
    "    profile_memory=True,  # 分析内存分配\n",
    "    with_stack=True  # 记录操作的调用堆栈信息\n",
    ") as profiler:\n",
    "    pipeline(\n",
    "        train_data=table,\n",
    "        # eval_data=table,\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### result\n",
    "    MVAE\n",
    "    15 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.732\n",
    "    --------------------------------------------------------------------------\n",
    "    Training ended!\n",
    "\n",
    "    2 layers 100 samples\n",
    "    10 epoch \n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.5193\n",
    "    --------------------------------------------------------------------------\n",
    "    30 epoch \n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.3101\n",
    "    --------------------------------------------------------------------------\n",
    "    Training ended!\n",
    "\n",
    "    2 layers 50 samples\n",
    "    10 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.4454\n",
    "    --------------------------------------------------------------------------\n",
    "    15 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.2469\n",
    "    --------------------------------------------------------------------------\n",
    "    40 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.1056\n",
    "    --------------------------------------------------------------------------\n",
    "\n",
    "    4 layers 50 samples\n",
    "    10 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.5834\n",
    "    --------------------------------------------------------------------------\n",
    "    15 epoch\n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.3808\n",
    "    --------------------------------------------------------------------------\n",
    "    30 epoch \n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.1588\n",
    "    --------------------------------------------------------------------------\n",
    "\n",
    "    4 layers 100 samples\n",
    "    30 epoch \n",
    "    --------------------------------------------------------------------------\n",
    "    Train loss: 33.16\n",
    "    --------------------------------------------------------------------------\n",
    "    Training ended!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Dict\n",
    "\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from pythae.models.base.base_utils import CPU_Unpickler\n",
    "\n",
    "def from_dict(config_dict: Dict[str, Any]) -> \"BaseConfig\":\n",
    "        \"\"\"Creates a :class:`~pythae.config.BaseConfig` instance from a dictionnary\n",
    "\n",
    "        Args:\n",
    "            config_dict (dict): The Python dictionnary containing all the parameters\n",
    "\n",
    "        Returns:\n",
    "            :class:`BaseConfig`: The created instance\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = MissIWAEConfig(**config_dict)\n",
    "        except (ValidationError, TypeError) as e:\n",
    "            raise e\n",
    "        return config\n",
    "\n",
    "def dict_from_json(json_path: Union[str, os.PathLike]) -> Dict[str, Any]:\n",
    "        try:\n",
    "            with open(json_path) as f:\n",
    "                try:\n",
    "                    config_dict = json.load(f)\n",
    "                    return config_dict\n",
    "\n",
    "                except (TypeError, json.JSONDecodeError) as e:\n",
    "                    raise TypeError(\n",
    "                        f\"File {json_path} not loadable. Maybe not json ? \\n\"\n",
    "                        f\"Catch Exception {type(e)} with message: \" + str(e)\n",
    "                    ) from e\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Config file not found. Please check path '{json_path}'\"\n",
    "            )\n",
    "\n",
    "def from_json_file(json_path: str) -> \"BaseConfig\":\n",
    "        \"\"\"Creates a :class:`~pythae.config.BaseConfig` instance from a JSON config file\n",
    "\n",
    "        Args:\n",
    "            json_path (str): The path to the json file containing all the parameters\n",
    "\n",
    "        Returns:\n",
    "            :class:`BaseConfig`: The created instance\n",
    "        \"\"\"\n",
    "        config_dict = dict_from_json(json_path)\n",
    "\n",
    "        config_name = config_dict.pop(\"name\")\n",
    "\n",
    "        return from_dict(config_dict)\n",
    "\n",
    "def load_model_config_from_folder(dir_path):\n",
    "        file_list = os.listdir(dir_path)\n",
    "\n",
    "        if \"model_config.json\" not in file_list:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Missing model config file ('model_config.json') in\"\n",
    "                f\"{dir_path}... Cannot perform model building.\"\n",
    "            )\n",
    "\n",
    "        path_to_model_config = os.path.join(dir_path, \"model_config.json\")\n",
    "        model_config = from_json_file(path_to_model_config)\n",
    "\n",
    "        return model_config\n",
    "\n",
    "def load_model_weights_from_folder(dir_path):\n",
    "        file_list = os.listdir(dir_path)\n",
    "\n",
    "        if \"model.pt\" not in file_list:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Missing model weights file ('model.pt') file in\"\n",
    "                f\"{dir_path}... Cannot perform model building.\"\n",
    "            )\n",
    "\n",
    "        path_to_model_weights = os.path.join(dir_path, \"model.pt\")\n",
    "\n",
    "        try:\n",
    "            model_weights = torch.load(path_to_model_weights, map_location=\"cpu\")\n",
    "\n",
    "        except RuntimeError:\n",
    "            RuntimeError(\n",
    "                \"Enable to load model weights. Ensure they are saves in a '.pt' format.\"\n",
    "            )\n",
    "\n",
    "        if \"model_state_dict\" not in model_weights.keys():\n",
    "            raise KeyError(\n",
    "                \"Model state dict is not available in 'model.pt' file. Got keys:\"\n",
    "                f\"{model_weights.keys()}\"\n",
    "            )\n",
    "\n",
    "        model_weights = model_weights[\"model_state_dict\"]\n",
    "\n",
    "        return model_weights\n",
    "    \n",
    "def load_custom_encoder_from_folder(dir_path):\n",
    "\n",
    "        file_list = os.listdir(dir_path)\n",
    "\n",
    "        if \"encoder.pkl\" not in file_list:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Missing encoder pkl file ('encoder.pkl') in\"\n",
    "                f\"{dir_path}... This file is needed to rebuild custom encoders.\"\n",
    "                \" Cannot perform model building.\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            with open(os.path.join(dir_path, \"encoder.pkl\"), \"rb\") as fp:\n",
    "                encoder = CPU_Unpickler(fp).load()\n",
    "\n",
    "        return encoder\n",
    "\n",
    "def load_custom_decoder_from_folder(dir_path):\n",
    "\n",
    "    file_list = os.listdir(dir_path)\n",
    "\n",
    "    if \"decoder.pkl\" not in file_list:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing decoder pkl file ('decoder.pkl') in\"\n",
    "            f\"{dir_path}... This file is needed to rebuild custom decoders.\"\n",
    "            \" Cannot perform model building.\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        with open(os.path.join(dir_path, \"decoder.pkl\"), \"rb\") as fp:\n",
    "            decoder = CPU_Unpickler(fp).load()\n",
    "\n",
    "    return decoder    \n",
    "\n",
    "def load_from_folder(model, dir_path):\n",
    "        \"\"\"Class method to be used to load the model from a specific folder\n",
    "\n",
    "        Args:\n",
    "            dir_path (str): The path where the model should have been be saved.\n",
    "\n",
    "        .. note::\n",
    "            This function requires the folder to contain:\n",
    "\n",
    "            - | a ``model_config.json`` and a ``model.pt`` if no custom architectures were provided\n",
    "\n",
    "            **or**\n",
    "\n",
    "            - | a ``model_config.json``, a ``model.pt`` and a ``encoder.pkl`` (resp.\n",
    "                ``decoder.pkl``) if a custom encoder (resp. decoder) was provided\n",
    "        \"\"\"\n",
    "\n",
    "        model_config = load_model_config_from_folder(dir_path)\n",
    "        model_weights = load_model_weights_from_folder(dir_path)\n",
    "        \n",
    "        encoder = load_custom_encoder_from_folder(dir_path)\n",
    "        decoder = load_custom_decoder_from_folder(dir_path)\n",
    "        \n",
    "        model = MissIWAE(model_config, encoder=encoder, decoder=decoder)\n",
    "        model.load_state_dict(model_weights)\n",
    "\n",
    "        return model\n",
    "\n",
    "last_training = sorted(os.listdir('./saved_models/power_test/imputated_ce'))[-1]\n",
    "model = load_from_folder(model, os.path.join('./saved_models/power_test/imputated_ce', last_training, 'final_model')).to(device)\n",
    "# print(f'model: {model.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 32.13945187641754\n"
     ]
    }
   ],
   "source": [
    "# valid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model.eval()\n",
    "valid_loss = []\n",
    "with torch.no_grad():\n",
    "    for inputs in DataLoader(table, batch_size=1024, num_workers=4, pin_memory=True):\n",
    "        x = inputs[\"data\"].cuda() # (bs, n_dims)\n",
    "        xb = inputs[\"data_one_hot\"].cuda()\n",
    "        mask = inputs[\"masks\"].cuda()\n",
    "        \n",
    "        xb[mask.bool()] = 0.5 # in xbhat, the missing values are represented by 0.5\n",
    "        \n",
    "        # self.mask = mask.unsqueeze(-1) # (bs, n_features, 1)\n",
    "        model.mask = mask.unsqueeze(-1).to(device=xb.device)\n",
    "        \n",
    "        encoder_output = model.encoder(xb)\n",
    "\n",
    "        mu, log_var = encoder_output.embedding, encoder_output.log_covariance\n",
    "\n",
    "        mu = mu.unsqueeze(1).repeat(1, model.n_samples, 1)\n",
    "        log_var = log_var.unsqueeze(1).repeat(1, model.n_samples, 1)\n",
    "        # print(f'mu : {mu.shape}')\n",
    "        # print(f'log_var : {log_var.shape}')\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "\n",
    "        z, _ = model._sample_gauss(mu, std)\n",
    "\n",
    "        recon_xb = model.decoder(z.reshape(-1, model.latent_dim))[\n",
    "            \"reconstruction\"\n",
    "        ].reshape(x.shape[0], -1, model.n_samples) # (bs, n_features, n_samples)\n",
    "        # print(f'recon_xb : {recon_xb.shape}')\n",
    "        x = x.reshape(recon_xb.shape[0], -1).unsqueeze(-1).repeat(1, 1, model.n_samples)\n",
    "        recon_loss = torch.zeros(recon_xb.size()[0], model.n_samples, device=recon_xb.device) # (bs, n_samples)\n",
    "        start = 0\n",
    "        for i in range(len(model.input_bins)):\n",
    "            recon_loss += F.cross_entropy(\n",
    "                recon_xb[:, start: start + model.input_bins[i], :],\n",
    "                x[:, i, :].long(),\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            start += model.input_bins[i]\n",
    "                \n",
    "        log_q_z = (-0.5 * (log_var + torch.pow(z - mu, 2) / (log_var.exp() + 10e-7))).float().sum(dim=-1) # (bs, n_samples)\n",
    "        log_p_z = -0.5 * (z ** 2).float().sum(dim=-1) # (bs, n_samples)\n",
    "\n",
    "        KLD = -(log_p_z - log_q_z)\n",
    "\n",
    "        log_w = -(recon_loss + KLD).float() # (bs, n_samples)\n",
    "        w_tilde = F.log_softmax(log_w, dim=1).exp().detach()\n",
    "\n",
    "        valid_loss.append(-(w_tilde * log_w).sum(1).mean())\n",
    "    \n",
    "print(f'valid_loss : {torch.stack(valid_loss).mean().item() / np.log(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv valid_loss : 32.83912683113089 \\\n",
    "absolute pe valid_loss : 32.13945187641754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from my_utils import Card, ErrorMetric, FillInUnqueriedColumns, GenerateQuery\n",
    "\n",
    "OPS = {\n",
    "    '>': np.greater,\n",
    "    '<': np.less,\n",
    "    '>=': np.greater_equal,\n",
    "    '<=': np.less_equal,\n",
    "    '=': np.equal\n",
    "}\n",
    "\n",
    "def eval_power_discrete(model):\n",
    "    rng = np.random.RandomState(1234)\n",
    "    count = 0\n",
    "    n_rows = table.tuples.shape[0]\n",
    "    qerrors = []\n",
    "\n",
    "    for i in range(3000):\n",
    "            \n",
    "        cols, ops, vals = GenerateQuery(original_data.columns, rng, original_data.data)\n",
    "        true_card = Card(original_data.data, cols, ops, vals)\n",
    "        # print(cols, ops, vals)\n",
    "        columns, operators, vals = FillInUnqueriedColumns(original_data, cols, ops, vals)\n",
    "                \n",
    "        ncols = len(original_data.columns)\n",
    "        \n",
    "        mask_i_list = [None] * ncols  # None means all valid.\n",
    "        for i in range(ncols):\n",
    "            \n",
    "            # Column i.\n",
    "            op = operators[i]\n",
    "            if op is not None:\n",
    "                # There exists a filter.\n",
    "                mask_i = OPS[op](columns[i].all_distinct_values,\n",
    "                                  vals[i]).astype(np.float32, copy=False)\n",
    "            else:\n",
    "                mask_i = np.ones(len(columns[i].all_distinct_values), dtype=np.float32)\n",
    "                \n",
    "            mask_i_list[i] = torch.as_tensor(mask_i, dtype=torch.bool, device=device).view(1, -1)\n",
    "            # print(f'mask_i: {mask_i_list[i].shape}')\n",
    "        \n",
    "        mask = torch.cat(mask_i_list, dim=1)\n",
    "        # print(f'mask: {mask.shape}')\n",
    "        xobs = torch.zeros(mask.size(), dtype=torch.float32, device=device)\n",
    "        # print(f'xobs: {xobs.shape}')\n",
    "        xobs[mask] = 0.5\n",
    "        # print(mask)\n",
    "        # break\n",
    "        probs = model.probe(xobs, mask, 10).detach().cpu().numpy().tolist()\n",
    "        prob = probs[0]\n",
    "        # print(f'prob: {prob}')\n",
    "        \n",
    "        \n",
    "        est_card = max(prob * n_rows, 1)\n",
    "        \n",
    "        if est_card > n_rows:\n",
    "            count += 1\n",
    "            est_card = n_rows\n",
    "            # print(f'prob {prob} true_card: {true_card}')\n",
    "            \n",
    "        qerror = ErrorMetric(est_card, true_card)\n",
    "        qerrors.append(qerror)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'{i} queries done')\n",
    "    \n",
    "    return count, qerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimation failed times: 8\n",
      "test results\n",
      "Median: 26.057259944782736\n",
      "90th percentile: 2506.5918770686994\n",
      "95th percentile: 10210.681563767039\n",
      "99th percentile: 98248.27999999905\n",
      "Max: 776636.0\n",
      "Mean: 4299.89007198345\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "count, qerrors = eval_power_discrete(model)\n",
    "\n",
    "print(f'estimation failed times: {count}')\n",
    "print('test results')\n",
    "print(f\"Median: {np.median(qerrors)}\")\n",
    "print(f\"90th percentile: {np.percentile(qerrors, 90)}\")\n",
    "print(f\"95th percentile: {np.percentile(qerrors, 95)}\")\n",
    "print(f\"99th percentile: {np.percentile(qerrors, 99)}\")\n",
    "print(f\"Max: {np.max(qerrors)}\")\n",
    "print(f\"Mean: {np.mean(qerrors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_entropy\n",
    "10 epoch\n",
    "estimation failed times: 2\n",
    "test results\n",
    "Median: 23.151113000960258\n",
    "90th percentile: 2567.3999999999996\n",
    "95th percentile: 10652.93222600411\n",
    "99th percentile: 109012.11886992674\n",
    "Max: 535608.0\n",
    "Mean: 4093.639562321854\n",
    "\n",
    "binary_cross_entropy\n",
    "10 epoch \n",
    "estimation failed times: 0\n",
    "test results\n",
    "Median: 28.51926446395437\n",
    "90th percentile: 2609.357427105609\n",
    "95th percentile: 11461.255020661672\n",
    "99th percentile: 124040.84624133495\n",
    "Max: 533867.357491531\n",
    "Mean: 4704.4605649417435\n",
    "binary_cross_entropy absolute pe\n",
    "10 epoch\n",
    "estimation failed times: 8\n",
    "test results\n",
    "Median: 26.057259944782736\n",
    "90th percentile: 2506.5918770686994\n",
    "95th percentile: 10210.681563767039\n",
    "99th percentile: 98248.27999999905\n",
    "Max: 776636.0\n",
    "Mean: 4299.89007198345\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vdvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
